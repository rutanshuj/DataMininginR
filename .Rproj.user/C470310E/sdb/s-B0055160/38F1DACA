{
    "collab_server" : "",
    "contents" : "IsPure <- function(data) {\n  length(unique(data[,ncol(data)])) == 1\n}\n\nEntropy <- function( vls ) {\n  res <- vls/sum(vls) * log2(vls/sum(vls))\n  res[vls == 0] <- 0\n  -sum(res)\n}\n\nInformationGain <- function( tble ) {\n  entropyBefore <- Entropy(colSums(tble))\n  s <- rowSums(tble)\n  entropyAfter <- sum (s / sum(s) * apply(tble, MARGIN = 1, FUN = Entropy ))\n  informationGain <- entropyBefore - entropyAfter\n  return (informationGain)\n}\n\nTrainID3 <- function(node, data) {\n  \n  node$obsCount <- nrow(data)\n  \n  #if the data-set is pure (e.g. all toxic), then\n  if (IsPure(data)) {\n    #construct a leaf having the name of the pure feature (e.g. 'toxic')\n    child <- node$AddChild(unique(data[,ncol(data)]))\n    node$feature <- tail(names(data), 1)\n    child$obsCount <- nrow(data)\n    child$feature <- ''\n  } else {\n    #calculate the information gain\n    ig <- sapply(colnames(data)[-ncol(data)], \n                 function(x) InformationGain(\n                   table(data[,x], data[,ncol(data)])\n                 )\n    )\n    #chose the feature with the highest information gain (e.g. 'color')\n    #if more than one feature have the same information gain, then take\n    #the first one\n    feature <- names(which.max(ig))\n    node$feature <- feature\n    \n    #take the subset of the data-set having that feature value\n    \n    childObs <- split(data[ ,names(data) != feature, drop = FALSE], \n                      data[ ,feature], \n                      drop = TRUE)\n    \n    for(i in 1:length(childObs)) {\n      #construct a child having the name of that feature value (e.g. 'red')\n      child <- node$AddChild(names(childObs)[i])\n      \n      #call the algorithm recursively on the child and the subset      \n      TrainID3(child, childObs[[i]])\n    }\n    \n  }\n  \n  \n  \n}\n\nlibrary(data.tree)\ndata(mushroom)\nmushroom\n\ntree <- Node$new(\"mushroom\")\nTrainID3(tree, mushroom)\nprint(tree, \"feature\", \"obsCount\")\n\n\nPredict <- function(tree, features) {\n  if (tree$children[[1]]$isLeaf) return (tree$children[[1]]$name)\n  child <- tree$children[[features[[tree$feature]]]]\n  return ( Predict(child, features))\n}\n\nPredict(tree, c(color = 'red', \n                size = 'large', \n                points = 'yes')\n)\n\n",
    "created" : 1516460316531.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4245004868",
    "id" : "38F1DACA",
    "lastKnownWriteTime" : 1516460904,
    "last_content_update" : 1516460904559,
    "path" : "~/R/DataMining/ID3.R",
    "project_path" : "ID3.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}